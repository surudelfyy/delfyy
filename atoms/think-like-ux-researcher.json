[
  {
    "id": "think-like-ux-researcher-heuristic-001",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Observe what people do, not what they say. Past behavior predicts future behavior; prioritize action research over intention research.",
    "rationale": "People confabulate reasons. Behavior depends on person and environment; in-context observation reveals authentic patterns.",
    "lens": ["Customer"],
    "level": "Product",
    "dimension": "Experience",
    "applies_when": ["context:user-research", "goal:understand-behavior"],
    "strength": "High",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-002",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Field research finds the right thing; usability testing checks the thing is right. They are complementary.",
    "rationale": "Field asks who/what/why; usability asks can they use it. Both are required for problem-solution fit and quality.",
    "lens": ["Customer"],
    "level": "Product",
    "dimension": "Quality",
    "applies_when": ["stage:product-development", "goal:validation"],
    "strength": "High",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-003",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Triangulate qual ('why') and quant ('what'); skinny data shows what, fat data shows why.",
    "rationale": "No single method suffices; combining methods produces reliable understanding.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:research-design", "goal:comprehensive-understanding"],
    "strength": "High",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-004",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Screen participants on past behaviors, not demographics; ask about specific actions.",
    "rationale": "Demographics correlate but don’t cause; past behaviors predict performance better.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:participant-recruitment", "goal:reliable-data"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-005",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Use theoretical sampling: select participants for insight potential; bias toward likely problem experiencers.",
    "rationale": "Representative samples dilute problem finding; discovery needs depth from small, targeted samples.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:qualitative-research", "goal:problem-discovery"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-006",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "For innovation, look beyond typical users to opposite/less obvious groups; question what job the product really does.",
    "rationale": "Develop/Deliver without Discover/Define skips innovation; unconventional users reveal broader needs.",
    "lens": ["Customer"],
    "level": "Strategy",
    "dimension": "Audience",
    "applies_when": ["goal:innovation", "stage:discovery"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-failuremode-001",
    "source": "Think Like a UX Researcher",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Automation of research removes live observation, hiding the 'why' and killing teachable moments.",
    "rationale": "Automated methods give outcomes but not behaviors; empathy and surprise require observation.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:remote-research", "signal:efficiency-pressure"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-failuremode-002",
    "source": "Think Like a UX Researcher",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Credulity: believing what users say without proof; response bias and cherry-picking corrupt findings.",
    "rationale": "Stated preferences rarely match behavior; observe behavior to avoid confirmation bias.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:user-interviews", "signal:opinion-heavy-data"],
    "strength": "High",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-failuremode-003",
    "source": "Think Like a UX Researcher",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Designing for 'everyone' removes constraints and focus, yielding 'everything for no one.'",
    "rationale": "Constraints foster creativity; niche focus enables validated learning before expansion.",
    "lens": ["Customer"],
    "level": "Strategy",
    "dimension": "Audience",
    "applies_when": ["signal:broad-target-market", "stage:early"],
    "strength": "High",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-failuremode-004",
    "source": "Think Like a UX Researcher",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Illusory superiority: 80% of firms think CX is superior; only 8% of customers agree.",
    "rationale": "Perception gap exists when relying on biased feedback; mature orgs observe real behavior to bridge say-do gap.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["signal:positive-internal-perception", "context:customer-experience"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-007",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Translate UX improvements into money; use conservative estimates for credibility.",
    "rationale": "Managers need quantified impact (sales lift, cost/time savings) to approve changes.",
    "lens": ["Business"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:stakeholder-communication", "goal:justify-design-changes"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-heuristic-008",
    "source": "Think Like a UX Researcher",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "A usability test is the best first UX activity in low-maturity orgs—reveals objectives, users, stakeholders, and appetite.",
    "rationale": "Acts as 'gateway drug' demonstrating value of user observation and builds momentum for research culture.",
    "lens": ["Customer", "Business"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:ux-maturity-low", "goal:build-ux-culture"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-pattern-001",
    "source": "Think Like a UX Researcher",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Number of tasks attempted matters more than participant count for finding usability problems; include low-skill users, multiple observers, varied tasks.",
    "rationale": "Many problems affect small percentages; task diversity boosts detection more than adding participants.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:usability-testing", "goal:problem-discovery"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  },
  {
    "id": "think-like-ux-researcher-failuremode-005",
    "source": "Think Like a UX Researcher",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Large-sample web surveys are unreliable due to coverage/non-response error; triangulate with behavioral data.",
    "rationale": "Respondents differ from non-respondents; big N doesn’t guarantee robustness without triangulation.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["context:survey-research", "signal:large-sample-confidence"],
    "strength": "Medium",
    "evidence_grade": "Secondary"
  }
]

