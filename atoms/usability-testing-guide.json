[
  {
    "id": "usability-testing-heuristic-001",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Usability testing fundamentally means observing real users interact with a product to identify usability issues. This empirical method moves beyond subjective opinions by collecting direct evidence of user behavior and pain points. It is not about whether a product functions technically, but rather how easily and effectively users can achieve their goals.",
    "rationale": "The process provides qualitative and quantitative data about ease of use. It's about how well the interface supports the user's goals. Usability testing uncovers problems that even experienced designers might overlook because they are too close to the product.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["assumptions:untested", "design:evaluating"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-002",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "For qualitative problem discovery, 5-8 users are sufficient to uncover 85% of major usability issues. This 'magic number' proposed by Jakob Nielsen often yields diminishing returns for problem identification beyond this point.",
    "rationale": "More users often surface the same issues repeatedly. The goal of qualitative testing is to identify problems, not to achieve statistical significance. Small samples are efficient for discovery; larger samples are needed for quantitative measurement.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:qualitative", "sample-size:determining"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-003",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "The 'think-aloud' protocol is the single most valuable technique for qualitative usability data. Encouraging users to vocalize their thoughts, feelings, and assumptions as they navigate provides rich insight into mental models and decision-making processes that automated methods cannot capture.",
    "rationale": "It uncovers underlying motivations, expectations, and points of confusion in real-time. The ability to ask 'why' immediately reveals root causes of struggles rather than just observing that struggles occurred.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:moderated", "insights:qualitative"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-004",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Test early and often with low-fidelity prototypes. Identifying and fixing design flaws in sketches, wireframes, or paper prototypes is significantly cheaper and faster than making changes to developed code. The goal is to learn as quickly as possible and pivot when necessary.",
    "rationale": "It's easier and cheaper to redraw a sketch than to rewrite code. Early testing prevents costly reworks and reduces development risk. Testing throughout the lifecycle rather than at the end aligns with Lean UX principles of 'building just enough to test.'",
    "lens": ["Feasibility", "Business"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["development:early-stage", "prototypes:available"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-005",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Recruiting the right participants is arguably the most critical step in usability testing. Testing with individuals who do not represent your target audience will lead to irrelevant or misleading findings. The goal is to find participants whose demographics, experience levels, and behaviors mirror those of your actual users.",
    "rationale": "Testing with wrong participants produces insights that don't apply to real users, leading to misguided design decisions. Use screener surveys with behavioral questions (not just demographics) to ensure representative recruitment.",
    "lens": ["Customer", "Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["recruitment:planning", "participants:selecting"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-006",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Define clear research objectives before testing. Without specific questions to answer and success metrics for each task, tests risk yielding unfocused or unactionable data. Articulate what you want to learn, what tasks test those hypotheses, and what defines success.",
    "rationale": "Poorly defined objectives lead to wasted time and ambiguous findings. Use SMART goals: Specific, Measurable, Achievable, Relevant, Time-bound. Clear objectives enable prioritization of issues and confident design decisions.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:planning", "objectives:missing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-007",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Combine qualitative and quantitative methods for a complete picture. Qualitative testing tells you 'why' problems exist; quantitative metrics tell you 'how prevalent or severe' they are. An imbalanced approach leads to an incomplete understanding.",
    "rationale": "Qualitative-only: you don't know how widespread a problem is. Quantitative-only: you know a problem exists but not why. Triangulate data from different sources to identify where to focus and validate solutions.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["analysis:conducting", "methods:selecting"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-008",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Usability testing reveals what users actually do, not what they say they do. Focus groups reveal stated opinions which can be influenced by group dynamics or social desirability. People often cannot accurately articulate their usability struggles or predict their own behavior.",
    "rationale": "Behavioral data from direct observation is fundamentally different from self-reported attitudes. For identifying interface problems, usability testing is vastly superior to asking users what they think they would do.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["method:selecting", "behavior:understanding"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-heuristic-009",
    "source": "Usability Testing Guide",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Link usability improvements to tangible business outcomes to demonstrate ROI. Track reduced support costs (fewer tickets × cost per ticket), increased conversion rates, improved retention, and decreased development rework to justify UX investment.",
    "rationale": "Without connecting improvements to business metrics, usability testing appears as a cost center rather than a value driver. Quantifiable ROI helps advocate for resources and demonstrates strategic value of UX efforts.",
    "lens": ["Business"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["roi:calculating", "stakeholders:convincing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-failuremode-001",
    "source": "Usability Testing Guide",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Testing too late in the development cycle is one of the most significant and costly mistakes. When design flaws are deeply embedded in developed code, fixing them is expensive and time-consuming, leading to difficult compromises, rushed fixes, or delayed launches.",
    "rationale": "High cost of change: fixing issues in developed code is far more expensive than in early designs. Teams may be resistant to extensive reworks after investing significant effort. The fix is to embrace early and frequent testing, even with sketches.",
    "lens": ["Feasibility", "Business"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["development:late-stage", "testing:delayed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-failuremode-002",
    "source": "Usability Testing Guide",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Recruiting the wrong participants produces irrelevant or misleading findings. Testing with internal employees, people too tech-savvy, or those unfamiliar with the domain leads to design decisions based on flawed assumptions about the actual user base.",
    "rationale": "Colleagues and friends familiar with the product provide biased insights. Use detailed screener questions focused on past behaviors (not self-reported skills) to filter participants who match target personas.",
    "lens": ["Customer", "Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["recruitment:conducting", "participants:internal"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-failuremode-003",
    "source": "Usability Testing Guide",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Leading participants or providing too much help introduces bias and prevents observing genuine struggles. The goal is to see how users perform without help, replicating real-world scenarios. Allow participants to struggle—their struggles reveal the most valuable usability problems.",
    "rationale": "Helping users guides them past problems that would otherwise be discovered. Use neutral, open-ended questions. Remind participants to 'think aloud' instead of offering assistance. The moderator's role is to observe, not interfere.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:moderated", "moderator:intervening"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-failuremode-004",
    "source": "Usability Testing Guide",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Conducting usability tests without clearly defined objectives yields unfocused, unactionable findings. You'll gather data but won't know what it means or how to act on it. Indicators: 'Let's just see what people think' or no clear success/failure criteria for tasks.",
    "rationale": "Without objectives, you can't prioritize issues or make confident decisions. The fix is to start with specific research questions aligned with product goals, define success for each task, and ensure team alignment on objectives.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:planning", "goals:vague"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-failuremode-005",
    "source": "Usability Testing Guide",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Not acting on findings is perhaps the biggest mistake. Usability testing is an investment whose ROI is only realized when insights are translated into concrete product improvements. This happens due to lack of resources, organizational silos, or skepticism.",
    "rationale": "Research without action is just data collection. The fix: create clear, actionable recommendations backed by video evidence, involve stakeholders early so they see users struggle firsthand, integrate issues into product backlog, and re-test after implementing changes.",
    "lens": ["Business", "Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["findings:complete", "implementation:stalled"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-pattern-001",
    "source": "Usability Testing Guide",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Usability testing process: (1) Define objectives, (2) Recruit representative participants, (3) Develop tasks and scenarios, (4) Prepare test environment, (5) Conduct sessions with think-aloud, (6) Analyze data and identify patterns, (7) Report findings with actionable recommendations.",
    "rationale": "This systematic approach ensures tests are efficient, produce actionable insights, and address specific design questions. Each step contributes to generating reliable findings that can be translated into concrete improvements.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["test:planning"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-pattern-002",
    "source": "Usability Testing Guide",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Iterative design process with usability testing: Analyze/Define → Design/Ideate → Prototype → Test → Analyze/Synthesize → Refine/Redesign → Repeat. Each cycle builds upon insights from the previous one, leading to continuous improvement.",
    "rationale": "Perfect designs rarely emerge in a single attempt—they evolve through continuous feedback. This cyclical approach ensures user feedback directly informs design decisions at every stage, reducing risk of costly reworks.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["development:ongoing", "iteration:needed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-pattern-003",
    "source": "Usability Testing Guide",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Method selection by goal: Moderated tests for deep qualitative 'why' insights on complex flows. Unmoderated tests for scale, speed, and quantitative validation. Remote for geographic reach and cost efficiency. In-person for rich non-verbal cues and physical prototypes.",
    "rationale": "Different methods serve different purposes. Moderated tests (5-8 users) identify problems and root causes. Unmoderated tests (20-30+ users) measure prevalence and validate at scale. Strategic combination yields both depth and breadth.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["method:selecting", "goals:defining"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-pattern-004",
    "source": "Usability Testing Guide",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Key usability metrics: Task Completion Rate (% who successfully complete task), Time on Task (efficiency), Error Rate (confusion points), Number of Clicks (navigation efficiency), Satisfaction Scores (SUS, SEQ, NPS for subjective experience).",
    "rationale": "These metrics provide quantitative evidence for prioritization and demonstrate improvement over time. Task completion rate is the most fundamental metric. Combine with qualitative observations to understand the 'why' behind the numbers.",
    "lens": ["Customer", "Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["measurement:planning", "metrics:selecting"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-pattern-005",
    "source": "Usability Testing Guide",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Jakob Nielsen's 10 Usability Heuristics for expert review: (1) Visibility of system status, (2) Match between system and real world, (3) User control and freedom, (4) Consistency and standards, (5) Error prevention, (6) Recognition rather than recall, (7) Flexibility and efficiency, (8) Aesthetic and minimalist design, (9) Help users recover from errors, (10) Help and documentation.",
    "rationale": "Expert reviews using heuristics can quickly identify many common usability violations before user testing, making user testing more efficient and focused. 3-5 evaluators independently reviewing against heuristics catches significant issues fast and cheap.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["review:expert", "evaluation:quick"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-signal-001",
    "source": "Usability Testing Guide",
    "type": "Signal",
    "purpose": "Detect",
    "claim": "System Usability Scale (SUS) is a validated 10-item questionnaire providing a single score (0-100) representing overall subjective usability. Average SUS score is around 68. Industry standard for benchmarking perceived usability across products and over time.",
    "rationale": "SUS is widely used, easy to administer, and highly reliable. It provides a quick measure that allows comparison against other products. Scores above 68 are above average; scores above 80 indicate excellent usability.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["satisfaction:measuring", "benchmarking:needed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-signal-002",
    "source": "Usability Testing Guide",
    "type": "Signal",
    "purpose": "Detect",
    "claim": "Poor usability indicators: High bounce rates (users leave quickly), low conversion rates (complex flows deter completion), increased support costs (users can't self-serve), negative reviews (frustrating experiences), reduced retention (users abandon for easier alternatives).",
    "rationale": "These business metrics are symptoms of underlying usability problems. Analytics showing high drop-off at specific points indicate where to focus qualitative testing to understand the 'why.' Connect usability improvements to these metrics for ROI.",
    "lens": ["Business", "Customer"],
    "level": "Operating",
    "dimension": "Value",
    "applies_when": ["problems:diagnosing", "metrics:declining"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-001",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Online retailer checkout optimization: Five-step checkout had 30% abandonment due to confusing optional upsells and unclear shipping options. Simplified to three-step checkout based on usability test findings → 15% increase in completed purchases, millions in additional revenue.",
    "rationale": "Demonstrates direct ROI of usability testing in e-commerce. Complex checkout processes are a major cause of cart abandonment. User observation revealed specific friction points that analytics alone couldn't explain.",
    "lens": ["Business", "Customer"],
    "level": "Product",
    "dimension": "Value",
    "outcome": "Worked",
    "context": ["ecommerce", "checkout", "conversion"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-002",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Project management SaaS analytics dashboard: Users struggled to customize reports and interpret data visualizations → low feature adoption. Simplified customization options and redesigned confusing charts based on test feedback → 40% increase in feature usage within two months.",
    "rationale": "Confirms importance of user-centric design for product stickiness in SaaS. Complex interfaces lead to underutilization of powerful features. Testing revealed specific customization and interpretation difficulties that prevented adoption.",
    "lens": ["Customer", "Business"],
    "level": "Product",
    "dimension": "Value",
    "outcome": "Worked",
    "context": ["saas", "feature-adoption", "dashboard"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-003",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Hospital EHR system: New system led to increased medical errors and physician burnout due to complex interface. Critical patient information was buried deep within multiple clicks. Redesign based on usability testing → 25% reduction in data entry errors, improved physician satisfaction.",
    "rationale": "In healthcare, usability is about patient safety, not just convenience. Poor usability can lead to misdiagnoses and medication errors. This demonstrates usability testing as risk mitigation with life-or-death stakes.",
    "lens": ["Customer", "Business"],
    "level": "Product",
    "dimension": "Value",
    "outcome": "Worked",
    "context": ["healthcare", "safety", "enterprise"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-004",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Airbnb trust and booking conversion: Early Airbnb faced low booking conversion due to trust issues. Testing revealed users needed clear trust indicators, high-quality photos were the single most important factor, and hidden fees caused friction. Solutions: professional photography program, enhanced review system, clearer pricing → significant increase in booking conversion, global growth.",
    "rationale": "Demonstrates how usability testing can build trust in transaction-heavy platforms. The focus on high-quality visuals and transparent information proved instrumental in overcoming critical adoption barriers.",
    "lens": ["Customer", "Business"],
    "level": "Product",
    "dimension": "Value",
    "outcome": "Worked",
    "context": ["marketplace", "trust", "conversion"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-005",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "[Healthcare.gov](http://healthcare.gov/) launch failure (2013): Catastrophic launch where users couldn't enroll for health insurance. Testing was done too late, with too few participants, not with representative users. Issues identified but not addressed before launch. Post-launch 'tech surge' team implemented rapid usability testing → site salvaged, 8+ million successful enrollments.",
    "rationale": "Stark reminder that neglecting proper usability testing, especially early and often, can lead to catastrophic failures. This case powerfully demonstrates the immense value of fixing usability even when it seems too late.",
    "lens": ["Feasibility", "Business"],
    "level": "Product",
    "dimension": "Process",
    "outcome": "Mixed",
    "context": ["government", "public-services", "late-testing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "usability-testing-example-006",
    "source": "Usability Testing Guide",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Microsoft Office Ribbon redesign: Feature-rich Office applications led to feature bloat and complexity. Users only used a small fraction of features, struggling to find functions buried in menus. Extensive usability research led to the Ribbon interface with contextual tabs and visual icons → improved feature discoverability, more consistent experience.",
    "rationale": "Demonstrates how usability testing can drive bold, transformative redesigns for established products. The sustained commitment to user research enabled Microsoft to modernize its flagship product despite the risk of user backlash.",
    "lens": ["Customer"],
    "level": "Product",
    "dimension": "Value",
    "outcome": "Worked",
    "context": ["enterprise", "feature-discovery", "redesign"],
    "strength": "High",
    "evidence_grade": "Primary"
  }
]

