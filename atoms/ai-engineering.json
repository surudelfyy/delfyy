[
  {
    "id": "ai-engineering-heuristic-001",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Evaluation is the most important and challenging part of AI engineering—build the pipeline first.",
    "rationale": "Foundation models are open-ended; only task-specific evaluation on your data reveals performance.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["ai:building", "evaluation:ad-hoc"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-002",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Finetuning is for form; RAG is for facts. Exhaust prompting and RAG before finetuning.",
    "rationale": "Finetuning teaches style/format; RAG grounds factuality. Finetuning new facts risks hallucinations.",
    "lens": ["Feasibility"],
    "level": "Product",
    "dimension": "Scope",
    "applies_when": ["finetuning:premature", "knowledge:missing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-003",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "In commoditized-model era, proprietary high-quality data is the durable moat.",
    "rationale": "Small, high-quality, relevant data beats large noisy sets; data flywheel is defensibility.",
    "lens": ["Business"],
    "level": "Strategy",
    "dimension": "*",
    "applies_when": ["moat:seeking", "data:undervalued"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-004",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Production AI is a system of models/retrievers/guardrails/caches—evaluate components independently.",
    "rationale": "Component-level eval isolates failures (retriever vs generator) enabling targeted fixes.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["system:complex", "debugging:needed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-005",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Design to collect explicit/implicit user feedback seamlessly; feedback fuels improvement and personalization.",
    "rationale": "Implicit signals (regens, early terminations, corrections) are critical data for flywheel and quality.",
    "lens": ["Customer", "Business"],
    "level": "Product",
    "dimension": "Process",
    "applies_when": ["feedback:missing", "flywheel:building"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-006",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Break complex tasks into chained subtasks; simpler prompts improve reliability and debugging.",
    "rationale": "Prompt chaining isolates failures and enables parallelization (classify → generate).",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["prompt:complex", "reliability:needed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-007",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Always manually inspect sample data first; highest value-to-prestige ratio in ML.",
    "rationale": "Humans spot anomalies/format issues distributions hide; prevents silent data failures.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["data:new", "inspection:skipped"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-008",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Use slice-based evaluation (by segment/query type/topic) to avoid Simpson’s paradox and uncover weaknesses.",
    "rationale": "Aggregate metrics can hide catastrophic failures for specific segments or inputs.",
    "lens": ["Customer", "Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["evaluation:aggregate-only", "failures:hidden"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-heuristic-009",
    "source": "AI Engineering",
    "type": "Heuristic",
    "purpose": "Evaluate",
    "claim": "Small finetuned open models can beat larger proprietary models on specific tasks—cheaper and faster.",
    "rationale": "Task-specific finetuning concentrates capacity, reducing cost/latency with better task fit.",
    "lens": ["Business", "Feasibility"],
    "level": "Product",
    "dimension": "Scope",
    "applies_when": ["cost:high", "task:specific"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-001",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Hallucination: self-delusion and mismatched knowledge cause confident falsehoods.",
    "rationale": "Model builds on its own wrong outputs or mimics knowledge it lacks; grounding/guardrails required.",
    "lens": ["Customer", "Feasibility"],
    "level": "Product",
    "dimension": "Value",
    "applies_when": ["facts:critical", "grounding:missing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-002",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "AI as Judge limitations: inconsistency, position/verbosity bias, criteria ambiguity; costly/slow.",
    "rationale": "AI judges are biased models; need oversight and cautious interpretation.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["evaluation:ai-judge", "oversight:missing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-003",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Benchmark contamination inflates scores; public benchmarks saturate—prioritize own data/tests.",
    "rationale": "High scores may reflect training leakage; only bespoke evals show real-world performance.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["benchmarks:trusted-blindly", "contamination:possible"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-004",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Indirect prompt injection hides malicious instructions in retrieved data sources.",
    "rationale": "Untrusted context can hijack models to leak data or bypass safety; needs filtering/validation.",
    "lens": ["Customer", "Feasibility"],
    "level": "Product",
    "dimension": "Scope",
    "applies_when": ["rag:deployed", "sources:untrusted"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-005",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Training solely on synthetic data risks model collapse—drifting from real distribution.",
    "rationale": "Synthetic amplifies generator biases; must mix with real human data.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["data:synthetic-only", "distribution:drifting"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-failuremode-006",
    "source": "AI Engineering",
    "type": "FailureMode",
    "purpose": "Warn",
    "claim": "Wrong chat template in finetuning causes silent, hard-to-debug failures.",
    "rationale": "Models expect specific tokens/structures; mismatched format yields unpredictable behavior.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["finetuning:executing", "template:mismatched"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-001",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Prompt → RAG → Finetune workflow: start cheapest/fastest, add grounding, only finetune for behavior/style.",
    "rationale": "Optimizes speed/cost/quality; teaches consistent behaviors when prompting/RAG insufficient.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["adaptation:planning"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-002",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "RAG architecture: Retriever (term/embedding/hybrid) + Generator (FM with query + retrieved context).",
    "rationale": "Hybrid search common: fast term retrieval then embedding rerank; chunking is key trade-off.",
    "lens": ["Feasibility"],
    "level": "Product",
    "dimension": "Scope",
    "applies_when": ["knowledge:needed", "hallucination:reducing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-003",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Agent architecture: planner (FM) decomposes tasks, selects tools, executes, observes, reflects; ReAct common.",
    "rationale": "Separates planning from execution; write actions need oversight due to safety risk.",
    "lens": ["Feasibility"],
    "level": "Product",
    "dimension": "Scope",
    "applies_when": ["tasks:multi-step", "tools:needed"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-004",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "LoRA: freeze base weights, train small adapters; reduces memory/cost; adapters merge at inference.",
    "rationale": "Enables finetuning large models on modest hardware; QLoRA adds quantization for more efficiency.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["finetuning:needed", "resources:limited"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-005",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Production AI progression: add RAG → guardrails (PII/toxicity) → model router/gateway → caches for latency → agent patterns.",
    "rationale": "Start simple, add components as needs emerge; router sends simple to cheap models; gateway unifies access.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["architecture:designing", "production:preparing"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-pattern-006",
    "source": "AI Engineering",
    "type": "Pattern",
    "purpose": "Evaluate",
    "claim": "Evaluation pipeline: component-level eval → clear rubric/examples → eval methods + curated slice-based test sets.",
    "rationale": "Guideline defines 'good'; tie metrics to business impact; validate rubrics with humans.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["evaluation:building"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-signal-001",
    "source": "AI Engineering",
    "type": "Signal",
    "purpose": "Detect",
    "claim": "Implicit feedback signals: early termination/regeneration (dissatisfaction), error corrections, direct edits (negative), rename/share (positive), deletion (negative).",
    "rationale": "Conversational AI yields rich implicit signals for quality monitoring and personalization.",
    "lens": ["Customer"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["feedback:collecting", "signals:implicit"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-signal-002",
    "source": "AI Engineering",
    "type": "Signal",
    "purpose": "Detect",
    "claim": "Key inference metrics: Time to First Token (prefill), Time Per Output Token (decode), throughput, cost/request.",
    "rationale": "Prefill is compute-bound; decode is memory-bandwidth-bound; metrics guide optimization trade-offs.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "applies_when": ["inference:optimizing", "performance:measuring"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-example-001",
    "source": "AI Engineering",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Stanford Alpaca distilled GPT-3 via 52k synthetic instruction pairs—fast/cheap bootstrapping.",
    "rationale": "Synthetic data can quickly create useful smaller models; best results mix with human data.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "outcome": "Worked",
    "context": ["research", "data:synthetic"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-example-002",
    "source": "AI Engineering",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "GitHub Copilot feedback: accept/ignore signals captured without interrupting flow.",
    "rationale": "Embedded feedback collection yields implicit positive/negative signals at scale.",
    "lens": ["Customer"],
    "level": "Product",
    "dimension": "Process",
    "outcome": "Worked",
    "context": ["B2B", "developer-tools"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-example-003",
    "source": "AI Engineering",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "LMSYS Chatbot Arena uses pairwise voting and Elo for human preference eval—comparisons beat absolute scores.",
    "rationale": "Humans judge relatively; crowdsourced head-to-head yields robust rankings.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "outcome": "Worked",
    "context": ["evaluation", "crowdsourced"],
    "strength": "High",
    "evidence_grade": "Primary"
  },
  {
    "id": "ai-engineering-example-004",
    "source": "AI Engineering",
    "type": "Example",
    "purpose": "Illustrate",
    "claim": "Speculative decoding: draft model proposes tokens; target model verifies in parallel—~2x speedup.",
    "rationale": "Draft+verify overcomes autoregressive bottleneck with minimal quality loss.",
    "lens": ["Feasibility"],
    "level": "Operating",
    "dimension": "Process",
    "outcome": "Worked",
    "context": ["inference", "optimization"],
    "strength": "High",
    "evidence_grade": "Primary"
  }
]

